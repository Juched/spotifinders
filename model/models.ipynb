{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Indexer(object):\n",
    "    def __init__(self):\n",
    "        self.objs_to_ints = {}\n",
    "        self.ints_to_objs = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str([str(self.get_object(i)) for i in range(0, len(self))])\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.objs_to_ints)\n",
    "\n",
    "    def get_object(self, index):\n",
    "        if (index not in self.ints_to_objs):\n",
    "            return None\n",
    "        else:\n",
    "            return self.ints_to_objs[index]\n",
    "\n",
    "    def contains(self, object):\n",
    "        return self.index_of(object) != -1\n",
    "\n",
    "    def index_of(self, object):\n",
    "        if (object not in self.objs_to_ints):\n",
    "            return -1\n",
    "        else:\n",
    "            return self.objs_to_ints[object]\n",
    "\n",
    "    def add_and_get_index(self, object, add=True):\n",
    "        if not add:\n",
    "            return self.index_of(object)\n",
    "        if (object not in self.objs_to_ints):\n",
    "            new_idx = len(self.objs_to_ints)\n",
    "            self.objs_to_ints[object] = new_idx\n",
    "            self.ints_to_objs[new_idx] = object\n",
    "        return self.objs_to_ints[object]\n",
    "\n",
    "class UnigramFeatureExtractor():\n",
    "    def __init__(self, indexer: Indexer):\n",
    "        self._indexer = indexer\n",
    "\n",
    "    def get_indexer(self) -> Indexer:\n",
    "        return self._indexer\n",
    "\n",
    "    def extract_features(self, sentence: List[str], add_to_indexer: bool = False) -> Counter:\n",
    "\n",
    "        unigram_list: List[str] = []  # Will contain non-unique list of all unigrams parsed from the sentence\n",
    "\n",
    "        for unigram in sentence:\n",
    "\n",
    "            index = self._indexer.add_and_get_index(unigram.lower(), add_to_indexer)\n",
    "\n",
    "            if (index != -1):  # If unigram didn't get added to the indexer (this occurs during the testing phase)\n",
    "                unigram_list.append(unigram.lower())\n",
    "\n",
    "        return Counter(unigram_list)\n",
    "    \n",
    "# Helper function to create feature vector from feature counter\n",
    "def get_feature_vector(feature_counter: Counter, feature_extractor) -> np.ndarray:\n",
    "\n",
    "    feature_vector = np.zeros(len(feature_extractor.get_indexer()) + 1)\n",
    "\n",
    "    for feature in feature_counter:\n",
    "        feature_idx = feature_extractor.get_indexer().index_of(feature)\n",
    "        feature_vector[feature_idx] = feature_counter[feature]\n",
    "\n",
    "    feature_vector[-1] = 1\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "uni_fv = UnigramFeatureExtractor(indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52xJxFP6TqMuO4Yt0eOkMz</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>205.863</td>\n",
       "      <td>216120</td>\n",
       "      <td>4</td>\n",
       "      <td>We don't talk about Bruno, no, no, no\\nWe don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3XOalgusokruzA5ZBA2Qcb</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.572</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>77.502</td>\n",
       "      <td>136267</td>\n",
       "      <td>1</td>\n",
       "      <td>Wheezy outta here\\nPushin' P\\nYeah, pushin' P,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02MWAaffLxlfxAUY7c5dvx</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.525</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>80.870</td>\n",
       "      <td>238805</td>\n",
       "      <td>4</td>\n",
       "      <td>(Don't stop, baby, you can go on through\\n(Don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5Z9KJZvQzH6PFmb8SNkxuk</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.691</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.395</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>150.087</td>\n",
       "      <td>212353</td>\n",
       "      <td>4</td>\n",
       "      <td>Baby back, ayy\\nCouple racks, ayy\\nCouple Gram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1r9xUipOqoNwggBpENDsvJ</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.783</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>77.011</td>\n",
       "      <td>173381</td>\n",
       "      <td>4</td>\n",
       "      <td>Look out for yourself\\n\\nI wake up to the soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4xkOaSrkexMciUUogZKVTS</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>171.447</td>\n",
       "      <td>297787</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>42Xba467wgGvYrR2EE6s0i</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.615</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.346</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>160.014</td>\n",
       "      <td>227527</td>\n",
       "      <td>4</td>\n",
       "      <td>Nay-nay-nay, nah, oh, oh\\n\\nSmoke cigarettes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3KyKxJ4P3pVCgaZwaq2rUC</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.741</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>123.006</td>\n",
       "      <td>212166</td>\n",
       "      <td>4</td>\n",
       "      <td>Let's burn it fucking down\\nYeah\\n\\nBack from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>161DnLWsx1i3u1JT05lzqU</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.721</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>145.867</td>\n",
       "      <td>217867</td>\n",
       "      <td>4</td>\n",
       "      <td>I know you're somewhere out there\\nSomewhere f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7hxHWCCAIIxFLCzvDgnQHX</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.142</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>140.042</td>\n",
       "      <td>195429</td>\n",
       "      <td>4</td>\n",
       "      <td>Tastes like a lemonade\\nFeels sweet, And then ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   track_id  danceability  energy  key  loudness  mode  \\\n",
       "0    52xJxFP6TqMuO4Yt0eOkMz         0.577   0.450    0    -8.516     0   \n",
       "1    3XOalgusokruzA5ZBA2Qcb         0.773   0.422    1    -4.572     0   \n",
       "2    02MWAaffLxlfxAUY7c5dvx         0.761   0.525   11    -6.900     1   \n",
       "3    5Z9KJZvQzH6PFmb8SNkxuk         0.741   0.691   10    -7.395     0   \n",
       "4    1r9xUipOqoNwggBpENDsvJ         0.728   0.783   11    -4.424     0   \n",
       "..                      ...           ...     ...  ...       ...   ...   \n",
       "97   4xkOaSrkexMciUUogZKVTS         0.548   0.847    1    -3.237     1   \n",
       "98   42Xba467wgGvYrR2EE6s0i         0.597   0.615    2    -6.346     1   \n",
       "99   3KyKxJ4P3pVCgaZwaq2rUC         0.728   0.741    6    -7.075     0   \n",
       "100  161DnLWsx1i3u1JT05lzqU         0.498   0.590    1    -4.721     0   \n",
       "101  7hxHWCCAIIxFLCzvDgnQHX         0.800   0.658    1    -6.142     0   \n",
       "\n",
       "     speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0         0.0834      0.357000          0.000000    0.1110   0.8300  205.863   \n",
       "1         0.1870      0.007830          0.006930    0.1290   0.4880   77.502   \n",
       "2         0.0944      0.440000          0.000007    0.0921   0.5310   80.870   \n",
       "3         0.0672      0.022100          0.000000    0.0476   0.8920  150.087   \n",
       "4         0.2660      0.237000          0.000000    0.4340   0.5550   77.011   \n",
       "..           ...           ...               ...       ...      ...      ...   \n",
       "97        0.1860      0.062200          0.000000    0.0816   0.1000  171.447   \n",
       "98        0.0421      0.030300          0.000000    0.3780   0.4670  160.014   \n",
       "99        0.0473      0.000582          0.002060    0.3300   0.3100  123.006   \n",
       "100       0.0320      0.511000          0.000000    0.1070   0.0784  145.867   \n",
       "101       0.0790      0.250000          0.000000    0.1110   0.4620  140.042   \n",
       "\n",
       "     duration_ms  time_signature  \\\n",
       "0         216120               4   \n",
       "1         136267               1   \n",
       "2         238805               4   \n",
       "3         212353               4   \n",
       "4         173381               4   \n",
       "..           ...             ...   \n",
       "97        297787               4   \n",
       "98        227527               4   \n",
       "99        212166               4   \n",
       "100       217867               4   \n",
       "101       195429               4   \n",
       "\n",
       "                                                lyrics  \n",
       "0    We don't talk about Bruno, no, no, no\\nWe don'...  \n",
       "1    Wheezy outta here\\nPushin' P\\nYeah, pushin' P,...  \n",
       "2    (Don't stop, baby, you can go on through\\n(Don...  \n",
       "3    Baby back, ayy\\nCouple racks, ayy\\nCouple Gram...  \n",
       "4    Look out for yourself\\n\\nI wake up to the soun...  \n",
       "..                                                 ...  \n",
       "97                                                 NaN  \n",
       "98   Nay-nay-nay, nah, oh, oh\\n\\nSmoke cigarettes, ...  \n",
       "99   Let's burn it fucking down\\nYeah\\n\\nBack from ...  \n",
       "100  I know you're somewhere out there\\nSomewhere f...  \n",
       "101  Tastes like a lemonade\\nFeels sweet, And then ...  \n",
       "\n",
       "[102 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load lyric data\n",
    "data = pd.read_csv('lyric_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    Şarkı Sözleri\\n\\nDinle\\n\\nAna Sonuçlar\\n\\nIt's...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['track_id'] == '7rglLriMNBPAyuJOMGwi39']['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "data.dropna(subset = ['lyrics'], inplace=True)\n",
    "data = data.astype({\"lyrics\": str}, errors='raise') \n",
    "\n",
    "# filter lyrics\n",
    "pre_filter_lyrics = data['lyrics'].tolist()\n",
    "lyrics = []\n",
    "\n",
    "for song in pre_filter_lyrics:\n",
    "    song = song.replace('\\n', ' ')\n",
    "    song = song.replace('.', ' ')\n",
    "    song = song.replace(',', ' ')\n",
    "    song = song.replace('(', ' ')\n",
    "    song = song.replace(')', ' ')\n",
    "    lyrics.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (101) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0a58e875e32c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfeature_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muni_fv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfeature_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_vector\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (101) into shape (1)"
     ]
    }
   ],
   "source": [
    "# get feature vectors\n",
    "feature_matrix = np.zeros((len(lyrics), len(uni_fv.get_indexer()) + 1))\n",
    "for i, song in enumerate(lyrics):\n",
    "    words = song.split(' ')\n",
    "    counter = uni_fv.extract_features(words, True)\n",
    "    \n",
    "    feature_vector = get_feature_vector(counter, uni_fv)\n",
    "    feature_vector = np.where(feature_vector > 0, 1, 0)\n",
    "    feature_matrix[i] = feature_vector\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # bag of words\n",
    "# CountVec = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
    "#                            stop_words='english')\n",
    "# #transform\n",
    "# Count_data = CountVec.fit_transform(lyrics)\n",
    " \n",
    "# #create dataframe\n",
    "# cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names())\n",
    "# print(cv_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danceability model\n",
    "X = feature_matrix\n",
    "y = data[['danceability']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=44)\n",
    "\n",
    "dance_reg = LinearRegression().fit(X_train, y_train)\n",
    "diff = dance_reg.predict(X_test) - y_test\n",
    "print(diff)\n",
    "print(diff.sum(axis=0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy model\n",
    "X = feature_matrix\n",
    "y = data[['energy']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=44)\n",
    "\n",
    "energy_reg = LinearRegression().fit(X_train, y_train)\n",
    "diff = energy_reg.predict(X_test) - y_test\n",
    "print(diff)\n",
    "print(diff.sum(axis=0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valence model\n",
    "X = feature_matrix\n",
    "y = data[['valence']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=44)\n",
    "\n",
    "valence_reg = LinearRegression().fit(X_train, y_train)\n",
    "diff = valence_reg.predict(X_test) - y_test\n",
    "print(diff)\n",
    "print(diff.sum(axis=0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"no way bro what is up bro\"\n",
    "sentence = sentence.replace('\\n', ' ')\n",
    "sentence = sentence.replace('.', ' ')\n",
    "sentence = sentence.replace(',', ' ')\n",
    "sentence = sentence.replace('(', ' ')\n",
    "sentence = sentence.replace(')', ' ')\n",
    "\n",
    "words = sentence.split(' ')\n",
    "counter = uni_fv.extract_features(words, False)\n",
    "\n",
    "feature_vector = get_feature_vector(counter, uni_fv)\n",
    "feature_vector = np.where(feature_vector > 0, 1, 0)\n",
    "feature_vector = np.reshape(feature_vector, (1, feature_vector.shape[0]))\n",
    "print(dance_reg.predict(feature_vector), energy_reg.predict(feature_vector), valence_reg.predict(feature_vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
